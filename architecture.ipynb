{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisualBacter\n",
    "\n",
    "```\n",
    "Detección de ETA's mediante vision computacional en redes nueronales convolucionales\n",
    "\n",
    "Escrito por:\n",
    "\n",
    "Juan Diego y George Giosue\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, BatchNormalization, Permute, LSTM, Reshape, Concatenate, Lambda, Add\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from os import scandir\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Local modules\n",
    "\n",
    "sys.path.insert(0, os.path.join(Path(os.getcwd()).parent.parent, 'modules'))\n",
    "\n",
    "import functs as fns\n",
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices(), \"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routes and File extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:\\Users\\brhiann\\Desktop\\repos\\passnet\\data\"\n",
    "\n",
    "std_ext = ['.jpg', '.png', '.jpeg']\n",
    "\n",
    "# Project tree\n",
    "\n",
    "ROUTES = {}\n",
    "\n",
    "with scandir(DATA_PATH) as files:\n",
    "    for file in files:\n",
    "        if os.path.isdir:\n",
    "            ROUTES[file.name] = {\n",
    "                'path': os.path.abspath(file),\n",
    "                'children': {}\n",
    "            }\n",
    "\n",
    "            if os.path.isdir(file.path):\n",
    "                with scandir(file.path) as subfiles:\n",
    "                    for subfile in subfiles:\n",
    "                        if os.path.isdir(subfile.path):\n",
    "                            ROUTES[file.name]['children'][subfile.name] = {\n",
    "                                'path': os.path.abspath(subfile),\n",
    "                                'children': {}\n",
    "                            }\n",
    "\n",
    "                            # images and data.txt\n",
    "\n",
    "                            with scandir(subfile.path) as subsubfiles:\n",
    "                                photos = []\n",
    "                                for subsubfile in subsubfiles:\n",
    "                                    current_ext = os.path.splitext(\n",
    "                                        subsubfile.name)[1]\n",
    "\n",
    "                                    if current_ext == '.txt':\n",
    "                                        ROUTES[file.name]['children'][subfile.name]['children']['data'] = os.path.abspath(\n",
    "                                            subsubfile)\n",
    "                                    elif current_ext in std_ext:\n",
    "                                        photos.append(\n",
    "                                            os.path.abspath(subsubfile))\n",
    "\n",
    "                                ROUTES[file.name]['children'][subfile.name]['children']['photos'] = photos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample factor  [float]\n",
    "PERCENTAGE_REDUCE = 0.15\n",
    "\n",
    "# Scale factor of expansible data [int]\n",
    "\n",
    "IMG_SHAPE = (128, 128)\n",
    "\n",
    "EXTENSIBLE = {\n",
    "    'value': True,\n",
    "    'q_images': 50, # 250\n",
    "}\n",
    "\n",
    "# Model\n",
    "\n",
    "MODEL_PARAMETERS = {\n",
    "    'losses': tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    'optimizer': 'adam',\n",
    "    'metrics': ['accuracy'],\n",
    "    'fit': {\n",
    "        'batches': {\n",
    "            'train': 0.7,\n",
    "            'test': 0.3,\n",
    "        },\n",
    "        'epochs': 10\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set and Extensible factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "DATA_SET = fns.join_paths_from_extensions(DATA_PATH, std_ext, [])\n",
    "\n",
    "q_images = fns.q_recursive_files(DATA_PATH, std_ext, 0)\n",
    "\n",
    "\n",
    "DATA_SET_EXTENSIBLE = EXTENSIBLE['q_images'] * \\\n",
    "    q_images if EXTENSIBLE['value'] else q_images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "                            SUMMARY\n",
    "\n",
    "    - Percentage of reduction: {PERCENTAGE_REDUCE*100} % Quality\n",
    "\n",
    "    - Scale factor of expansible data [{EXTENSIBLE['value']}]:\n",
    "        factor: {EXTENSIBLE['q_images']}\n",
    "\n",
    "\n",
    "        - N° of samples:\n",
    "\n",
    "            - Images:\n",
    "                {q_images} => {DATA_SET_EXTENSIBLE}\n",
    "\n",
    "    - Batches weight:\n",
    "        Train: {MODEL_PARAMETERS['fit']['batches']['train']}\n",
    "        Test: {MODEL_PARAMETERS['fit']['batches']['test']}\n",
    "\"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Feature Columns\n",
    "\n",
    "class_names = [\n",
    "    (index, key) for index, key in enumerate(ROUTES.keys())\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unaltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for dse in DATA_SET:\n",
    "    class_name = dse.split('\\\\')[-2]\n",
    "    data.extend(fns.imgs_to_array(\n",
    "        src=dse,\n",
    "        callback=lambda source: labels.append(class_name),\n",
    "        check_file=fns.pass_file,\n",
    "        extensions=std_ext\n",
    "    ))\n",
    " \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data) > 0:\n",
    "    data.clear()\n",
    "    labels.clear()\n",
    "\n",
    "for dse in DATA_SET:\n",
    "    class_name = dse.split('\\\\')[-2]\n",
    "    for img_reduce in fns.reduce_flow(\n",
    "        src=dse,\n",
    "        ext=std_ext,\n",
    "        dim=cv2.IMREAD_UNCHANGED,\n",
    "        callback=lambda img: labels.append(\n",
    "            fns.search_in_list(class_names, class_name)\n",
    "        ),\n",
    "        conf={\n",
    "            'same_scale': False,\n",
    "            'factor': {\n",
    "                'size': IMG_SHAPE,\n",
    "                'fx': 0.5,\n",
    "                'fy': 0.7,\n",
    "                'interpolation': cv2.INTER_AREA\n",
    "            }\n",
    "        }\n",
    "    ):\n",
    "        data.append(img_reduce)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1m estimation -> 200x images\n",
    "# 4m estimation -> 600x images\n",
    "# 2m estimation -> 400x images\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "data = fns.extendible_flow(\n",
    "    images=data,\n",
    "    image_data_generator=datagen,\n",
    "    u_quantity=EXTENSIBLE['q_images']\n",
    ")\n",
    "\n",
    "labels = [ np.repeat(label, EXTENSIBLE['q_images']) for label in labels ]\n",
    "\n",
    "labels = fns.merge(labels)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(data) == len(labels), 'The data does not match in size'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 16\n",
    "\n",
    "fns.show_img(index, data, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
    "    data,\n",
    "    labels,\n",
    "    test_size=MODEL_PARAMETERS['fit']['batches']['test']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    N° train data: {len(train_data)} type: {type(train_data)}\n",
    "    N° train labels: {len(train_labels)} type: {type(train_labels)}\n",
    "\n",
    "    N° test data: {len(test_data)} type: {type(test_data)}\n",
    "    N° test labels: {len(test_labels)} type: {type(test_labels)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "INPUT_SHAPE = IMG_SHAPE + (3,)\n",
    "\n",
    "activation = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = activation, padding = 'same', input_shape = INPUT_SHAPE))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = activation, kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(len(class_names), activation = 'softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, 'model_arch.png', show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=MODEL_PARAMETERS['metrics'],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, train_labels, epochs=300, \n",
    "                    validation_data=(test_data, test_labels), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimagename = 'diego_h'\n",
    "\n",
    "testimage = cv2.imread(fr'C:\\Users\\brhiann\\Desktop\\repos\\passnet\\test\\{testimagename}.jpg', cv2.IMREAD_UNCHANGED)\n",
    "# 128 x 128\n",
    "\n",
    "testimage = cv2.resize(testimage, IMG_SHAPE)\n",
    "\n",
    "testimage = cv2.cvtColor(testimage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(testimage)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "testimagse = np.array([testimage])\n",
    "\n",
    "predictions = model.predict(testimagse)\n",
    "\n",
    "index_max = np.argmax(predictions[0])\n",
    "index_min = np.argmin(predictions[0])\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    The prediction is [MAX ARG]: {class_names[index_max\n",
    "    ][1]}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS_PATH = os.path.join(Path(os.getcwd()).parent.parent, 'models')\n",
    "\n",
    "MODEL_EXTENSION = \"h5\"\n",
    "\n",
    "MODEL_NAME = f\"model_{DATA_SET_EXTENSIBLE}_{IMG_SHAPE[0]}x_3_{str(round(test_acc, 4)*10000).split('.')[0]}_mc\"\n",
    "\n",
    "MODEL_FULL_NAME = f\"{MODEL_NAME}.{MODEL_EXTENSION}\"\n",
    "\n",
    "\n",
    "model.save(os.path.join(MODELS_PATH, MODEL_FULL_NAME))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded =tf.keras.models.load_model(os.path.join(MODELS_PATH, MODEL_NAME + '.' + MODEL_EXTENSION))\n",
    "\n",
    "\n",
    "#Convert to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_loaded)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "#Save the model.\n",
    "\n",
    "with open(f'{os.path.join(MODELS_PATH, MODEL_NAME)}.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7077c62dbc3425e67cc439db09f7291a8b966dee69dfb6e4d096cef9462d1e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
